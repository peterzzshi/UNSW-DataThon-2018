{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============ Datathon INSTRUCTIONS and INFORMATION ============\n",
    "\n",
    "Challenge: SkyHigh Books want to know in 2018 what readers will rate their books that they publish. You are given data from 2017, where you know what readers read and what rating each user provided on average to all books they read.\n",
    "\n",
    "Your job is 4 fold:\n",
    "\n",
    "Predict what readers will rate on average in 2018 on all books they will read in 2017 + 2018. Use the wishlist of books readers want to read in 2018 and what they have already read in 2017 as a starting point. SkyHigh Books wants to know this information, as they want to market directly to readers who either have higher potential average scores on all books, or lower scores.\n",
    "\n",
    "SkyHigh Books wants to know why some books in 2017 or 2018 (predict which books) have good or bad overall ratings. Is it certain words in the book? The genre of the book? The price in 2017 / 2018? Where it was sold? Why do some books on average have a higher rating than other books?\n",
    "\n",
    "SkyHigh Books wants to maintain a good online presence on book review sites (hence we want to predict user averages), and so they want you to tell them how they can lift overall global reader satisifcation (not just each individual user, but overall).\n",
    "\n",
    "Provide confidence bounds on your predictions. How much % are you sure your predictions are true or correct? Is the results plausible? Does the data seem plausible? (Ie do the word count follow some Power Law Distribution?)\n",
    "\n",
    "**Datasets**\n",
    "\n",
    "You are provided with 6 datasets:\n",
    "\n",
    "1. **Books Information**\n",
    "2. **Genres Mapping**\n",
    "3. **User Data**\n",
    "4. **Words in Book**\n",
    "5. **Words Mapping**\n",
    "6. **Example Submissions**\n",
    "\n",
    "------\n",
    "\n",
    "1. **Books Information** Actual info on books. Book ID, Barcode, difficulty (average *perceieved* reading difficulty of book --> 1 = easy, 5 = hard).\n",
    "2. **Genres Mapping** Maps Genre IDs to real Genre types (eg Science)\n",
    "3. **User Data** User's data on average ratings and what they read in 2017 + wishlist for 2018.\n",
    "4. **Words in Book** What are the words in the actual book.\n",
    "5. **Words Mapping** Actual words mapped to word ID\n",
    "6. **Example Submissions** Shows an example of what you need to provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn import datasets, metrics\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## loading data\n",
    "Books_Information = pd.read_csv('Books information.csv')\n",
    "User_Data = pd.read_csv('User Data.csv').replace(\"Not specified\", np.nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Books_Information.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_2017 = User_Data.iloc[:, [0, 1, 2, 4]]\n",
    "arr_2017 = [[columns[0], columns[1], int(book), float(columns[3])] for columns in user_2017.values for book in columns[2].split(', ')]\n",
    "user_2017 = pd.DataFrame(arr_2017, columns=user_2017.columns)\n",
    "\n",
    "user_2018 = User_Data.iloc[:, [0, 1, 3]]\n",
    "arr_2018 = [[columns[0], columns[1], int(book)] for columns in user_2018.values for book in columns[2].split(', ')]\n",
    "user_2018 = pd.DataFrame(arr_2018, columns=user_2018.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = user_2017.merge(Books_Information, left_on='User Read Books (2017)', right_on='Book ID')\n",
    "df_2018 = user_2018.merge(Books_Information, left_on='User Read Books (2018)', right_on='Book ID')\n",
    "\n",
    "df_2017 = df_2017[[\"User ID\", \"User Read Books (2017)\", \"User Difficulty Choice\", \"Book Genre\", \"Difficulty (Reader suggested)\", \"Number Of Words\", \"Price (2017)\", \"Most Sold At\", \"Number Sold\", \"Average Rating (2017)\"]].rename(columns={'User Read Books (2017)': 'Book', 'Price (2017)': 'Price', 'Average Rating (2017)': \"Rating\"})\n",
    "df_2018 = df_2018[[\"User ID\", \"User Read Books (2018)\", \"User Difficulty Choice\", \"Book Genre\", \"Difficulty (Reader suggested)\", \"Number Of Words\", \"Price (2018)\", \"Most Sold At\", \"Number Sold\"]].rename(columns={'User Read Books (2018)': 'Book', 'Price (2018)': 'Price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_2017.iloc[:, 2:8].values\n",
    "y = df_2017.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Taking care of missing data\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(X[:, 0].reshape(-1, 1))\n",
    "X[:, 0] = imputer.transform(X[:, 0].reshape(-1, 1)).round().reshape(-1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "X[:, 5] = labelencoder.fit_transform(X[:, 5])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1, 5])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.18977373, -0.18131846, -0.18040845, ..., -0.70603171,\n",
       "         1.35861619,  0.6655698 ],\n",
       "       [-0.18977373, -0.18131846, -0.18040845, ..., -0.70603171,\n",
       "         1.35861619,  0.6655698 ],\n",
       "       [-0.18977373, -0.18131846, -0.18040845, ..., -0.70603171,\n",
       "         1.35861619,  0.6655698 ],\n",
       "       ..., \n",
       "       [-0.18977373, -0.18131846, -0.18040845, ..., -1.41941219,\n",
       "        -0.00531204, -0.95661034],\n",
       "       [-0.18977373, -0.18131846, -0.18040845, ..., -1.41941219,\n",
       "        -0.00531204, -0.95661034],\n",
       "       [-0.18977373, -0.18131846, -0.18040845, ...,  0.00734876,\n",
       "         0.89903934,  0.99398602]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X = sc_X.fit_transform(X)\n",
    "sc_y = StandardScaler()\n",
    "y = sc_y.fit_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
